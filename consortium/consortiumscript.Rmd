---
title: "ConsortiumStuff"
output: html_document
---

Creating dataset:

```{r global_options, include=FALSE}
#knitr::opts_chunk$set(fig.width=12, fig.height=8, fig.path='~/Dropbox/PhDthesis/Figures/', warning=FALSE, message=FALSE,cache=T)
files=readRDS("~/Dropbox/mash_data.rds")
library('dplyr')
```


```{r,eval=FALSE,echo=FALSE}

duplicate_snp=which(duplicated(files$snp))
unique_snp=files$snp[-duplicate_snp]
sum(duplicated(files$snp))
sum(duplicated(unique_snp))
length(unique_snp)

beta=data.frame(files[-duplicate_snp,c(1,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30,32)],stringsAsFactors = F)
se=data.frame(files[-duplicate_snp,c(1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31,33)],stringsAsFactors = F)

sum(duplicated(beta$snp))

length(intersect(beta$snp,unique_snp))/length(union(beta$snp,unique_snp))

##note how I corectly skip out all the duplicated rs12186596 

beta[285511:285515,c(1:5)]
files[351046:351048,c(1:10)]
z=beta[,-1]/se[,-1]
beta.table=data.frame(beta[,-1],row.names=unique_snp)
se.table=data.frame(se[,-1],row.names=unique_snp)
z.table=data.frame(z,row.names=unique_snp)

head(beta.table/se.table)[,1:5]
head(z.table[,1:5])

write.table(beta.table,"betamatched.txt")
write.table(se.table,"se.matched.txt")
write.table(z.table,"z.matched.txt")
````


Now let's proceed as in mash, selecting the 'maxes' from a set of the top 1000:

```{r,eval=FALSE}
z.stat=read.table("z.matched.txt",header = TRUE)

v.j=matrix(rep(1,ncol(z.stat)*nrow(z.stat)),ncol=16,nrow=nrow(z.stat))
max.z=cbind(z.stat,maxz=apply(z.stat,1,function(x){max(abs(x))}))
max.z.sort=max.z[order(max.z[,"maxz"],decreasing=T),]
###use these strongest 1000 to build covariance matrices
maxes=max.z.sort[1:1000,-17]
image(cor(maxes))

write.table(maxes,"maxz.txt",col.names=FALSE,row.names=FALSE)
```

Now run SFA:

```{r,eval=FALSE}
#system('/Users/sarahurbut/miniconda3/bin/sfa -gen ./maxz.txt -g 1000 -n 16 -o consortiumz i -k 5')
library('mash')

factor.mat=as.matrix(read.table("consortiumz_F.out"))
lambda.mat=as.matrix(read.table("consortiumz_lambda.out"))


library('mash')
library('ExtremeDeconvolution')

max.z=read.table("maxz.txt")
max.v=matrix(rep(1,ncol(max.z)*nrow(max.z)),ncol=16,nrow=nrow(max.z))
dim(max.z)
ms=deconvolution.em.with.bovy(max.z,factor.mat,max.v,lambda.mat,K=3,P=3)
saveRDS(ms,"maxstepbovy.rds")
```

Now we want to compute the covariance matrices using the max step:
```{r,eval=FALSE}
ms=readRDS("maxstepbovy.rds")
A="consortium"
covmash=compute.hm.covmat.all.max.step(max.step = ms,b.hat = z.stat,se.hat = v.j,t.stat = max.z,Q = 5,lambda.mat = lambda.mat,A = "test",factor.mat = factor.mat,zero = T,power = 2)$covmat

set.seed(123)
index=sample(1:nrow(z.stat),50000,replace=F)
write.table(index,"index.txt")

index=read.table("index.txt")[,1]

train.t=z.stat[index,]
se.train=v.j[index,]



compute.hm.train.log.lik.pen(train.b = train.t,se.train = se.train,covmat = covmash,A=A,pen=1)

```

Let's examine the patterns of covariance and the hierarchical weights and any patterns of tissue specificity.

Let's look at the covariance patterns captured.  
```{r covmats, echo=FALSE}
library('mashr')
A="consortium"
covmat=readRDS("../Data/covmatconsortium.rds")
pis=readRDS(paste0("../Data/pis",A,".rds"))$pihat
pi.mat=data.frame(matrix(pis[-length(pis)],ncol=17+9,byrow=TRUE))

z.stat=read.table("z.matched.txt",header=TRUE)
post.means=read.table("../Data/allmeans.txt")[,-1]
lfsr.mash=read.table("../Data/giant3lfsr.txt")[,-1]
lfsr=lfsr.mash
names=unlist(lapply(colnames(z.stat),function(x){strsplit(x,"_")[[1]][2]}))
colnames(post.means)=colnames(lfsr.mash)=colnames(lfsr)=names
colnames(pi.mat)=c("ID","X'X","SVD","F1","F2","F3","F4","F5","SFA_Rank5",c(names,"ALL"))

barplot(colSums(pi.mat),main='MASH',las=2)


j=1000
k=3
cov=covmat
b.test=z.stat
se.test=matrix(rep(1,ncol(b.test)*nrow(b.test)),nrow(b.test),ncol=ncol(b.test))


b.mle=as.vector(t(b.test[j,]))##turn i into a R x 1 vector
V.gp.hat=diag(se.test[j,])^2
V.gp.hat.inv <- solve(V.gp.hat)
all.arrays=post.array.per.snp(j=j,covmat = cov,b.gp.hat = b.test,se.gp.hat = se.test)


U.gp1kl <- (post.b.gpkl.cov(V.gp.hat.inv, cov[[k]]))
mu.gp1kl <- as.array(post.b.gpkl.mean(b.mle, V.gp.hat.inv, U.gp1kl))
#(all.arrays$post.means[k,])
all.equal(as.numeric(all.arrays$post.means[k,]),as.numeric(mu.gp1kl))
all.equal(as.numeric(all.arrays$post.covs[k,]),as.numeric(diag(U.gp1kl)))
##Now, check to make sure weighting is correct


log.lik.snp=log.lik.func(b.mle,V.gp.hat,cov)
log.lik.minus.max=log.lik.snp-max(log.lik.snp)
#log.pi=log(pis)
#s=log.lik.minus.max+log.pi
exp.vec=exp(log.lik.minus.max)
post.weights=t(exp.vec*pis/sum(exp.vec*pis))
all.equal(as.numeric(post.means[j,]),as.numeric(post.weights%*%all.arrays$post.means))

##Check LFSR for a given tissue

r=3

pnorm(0,mean = mu.gp1kl[r],sd = sqrt(diag(U.gp1kl)[r]),lower.tail = FALSE)## and so an LFSR of 0.02 makes perfect sense because post.weight at this component is 0.98.
#show that this is in the array correctly
all.arrays$post.ups[k,r]

pnorm(0,mean = mu.gp1kl[r],sd = sqrt(diag(U.gp1kl)[r]),lower.tail = T)## and so an LFSR of 0.02 makes perfect sense because post.weight at this component is 0.98.
#show that this is in the array correctly
all.arrays$post.downs[k,r]

#plot(as.matrix(lfsr.mash[j,]),as.matrix(apply(rbind(post.weights%*%all.arrays$post.ups,post.weights%*%all.arrays$post.downs),2,function(x){1-max(x)})))

covmat=readRDS("../Data/covmatconsortium.rds")

for(i in 2:9){
   ifile <- paste0(i,'_eigen.png')
    pdf(ifile)
#for(i in c(2:9)){
x=cov2cor(covmat[[i]]) 
v=svd(x)$v

  colnames(v)=rownames(v)=names
max.effect=sign(v[,1][which.max(abs(v[,1]))])
barplot(max.effect*v[,1],las=2,main=paste0("EigenVector1ofUk=",i),col=i-1,cex.names=2)

dev.off()
}
system('montage -geometry 100% -tile 3x3 ./*_eigen.png ~/Dropbox/PhDThesis/Figures/compiledeigenconsortium.png')
```

We can see that `r sum(colSums(pi.mat[,1:9]))` proportion of the prior weight is assigned to the learned matrices. Looks good!

```{r,echo=FALSE,eval=T}
library(gplots)
library(ggplot2)
library(ggplot2)
library('colorRamps')
#install.packages("fields")
library(fields)
for(k in c(2,3,9)){
 
  x=cov2cor(abs(covmat[[k]]))/abs(max(diag(cov2cor(covmat[[k]]))))
x[lower.tri(x)] <- NA
colnames(x)=rownames(x)=colnames(z.stat)
      heatmap.2(x,#symm=T,
                dendrogram="none",density="none",trace="none",col=blue2green,Rowv=FALSE,Colv=FALSE,
                main=paste0("HeatMapofNormalizedofCov2CorU",k),
                cexRow=1,cexCol=1,
                breaks=seq(0,1,by=0.01)
                )
      }

# smat=abs(cov2cor(covmat[[k]]))
# smat[lower.tri(smat)] <- NA
# colnames(smat)=rownames(smat)=colnames(z.stat)
# 
# heatmap.2(smat,#symm=TRUE,
#           Rowv=FALSE,Colv=FALSE,
#           dendrogram="none",density="none",trace="none",#col=redblue,
#           col=blue2green(256),
#           main=paste0("Cov2CorUk2"),
#           cexRow=0.5,cexCol=0.5,cex.main=0.5)
# 
#
# for(k in 2:9){
#    ifile <- paste0(k,'_allheatmaps.png')
#     pdf(ifile)
#   x=covmat[[k]]
#   colnames(x)=colnames(z.stat)
#   rownames(x)=colnames(z.stat)
# heatmap.2(x/max(diag(covmat[[k]])),Rowv=FALSE,Colv=FALSE,symm=TRUE,dendrogram="none",density="none",trace="none",col=redblue(256),main=paste0("HeatMapofNormalizedUk",k),cexRow=0.5,cexCol=0.5,symbreaks=T,key=ifelse(k==2,TRUE,FALSE),cex)
# dev.off()

# }
#
# system('montage -geometry 100% -tile 3x3 ./*_allheatmaps.png ./kushalcompiledheatmaps.png')


# for(i in 2:9){
#    ifile <- paste0(i,'_eigen.png')
#     pdf(ifile)
for(i in c(2:9)){

v=svd(covmat[[i]])$v
  colnames(v)=rownames(v)=names
  max.effect=sign(v[,1][which.max(abs(v[,1]))])
  barplot(v[,1]/v[,1][which.max(abs(v[,1]))],cex.names=1.0,las=2,main=paste0("EigenVector1ofUk=",i))
  #barplot(max.effect*v[,1],las=2,main=paste0("EigenVector1ofUk=",i),col=i-1,cex.names=0.5)

#dev.off()
}
# system('montage -geometry 100% -tile 3x3 ./*_eigen.png ./compiledeigen.png')


```


Do we see patterns of specificity? It appears that specificity to one subgroup is very rare, since the correlation structure is so rich. Of note, schizophrenia and height stand out. 
Let's look at tissue specific:


```{r,echo=FALSE}

plot_ts=function(tissuename,lfsr,curvedata,thresh=0.05,subset=1:44){
  index_tissue=which(colnames(lfsr) %in% tissuename);

  ##create a matrix showing whether or not lfsr satisfies threshold
  sigmat = lfsr <= thresh;
  sigs=which(rowSums(sigmat[,index_tissue,drop=FALSE])==length(tissuename) & rowSums(sigmat[,-index_tissue,drop=FALSE])==0)
  
   iplotCurves(curvedata[sigs,subset],chartOpts=list(curves_xlab="Tissue",curves_ylab="curvedata"))}




thresh=0.05
dist=as.matrix(lfsr)<=thresh

ones=which(rowSums(dist)==1)
#plot tspec
barplot(apply(lfsr[which(rowSums(lfsr<=thresh)==1),],2,function(x){sum(x<=thresh)}),las=2,main=paste0("Number of SNPs with LFSR<",0.05," in Single subgroup"),cex.names=1)
```

How many associations do we call significant at an LFSR of 0.05? `r sum(lfsr.mash<0.05)` which is `r mean(lfsr.mash<0.05)` part of the data. When we plot t-spec by subgroup, we see that subgroup specific effects are rare and of small magnitude because of the sharing among tissues for a given fold change difference.

What about in ash?

```{r ashscript}
#ashmeans=read.table("univariateash.pm.txt")
ashlfsr=read.table('univariateash.lfsr.txt')

#dim(ashmeans)
dim(ashlfsr)

sum(ashlfsr<0.05)
mean(ashlfsr<0.05)
```


```{r eval=FALSE}
colnames(lfsr.mash)=names
rownames(lfsr.mash)=rownames(z.stat)
dist=lfsr.mash<0.05;
lapply(seq(1:ncol(lfsr.mash)),function(x){
  a=rownames(lfsr.mash)[which(rowSums(dist)==1&lfsr.mash[,x]<0.05)];
  lfsr.val=lfsr.mash[a,x]
  df=data.frame(lfsr.mash[a,x])
  rownames(df)=a
  write.table(df,paste0("../Data/traitspec/traitspec",colnames(lfsr.mash)[x],".txt"))})

lapply(seq(1:ncol(lfsr.mash)),function(x){
  a=rownames(lfsr.mash)[which(lfsr.mash[,x]<0.05)];
  lfsr.val=lfsr.mash[a,x]
  df=data.frame(lfsr.mash[a,x])
  rownames(df)=a
  write.table(df,paste0("../Data/significant/",colnames(lfsr.mash)[x],"significantin.txt"))})


```

##Confirmation of Results##
As an example confirmation, https://www.snpedia.com/index.php/Rs1042725 found nature SNP rs1042725 is associated with height (P = 4E-8) in a study involving over 20,000 individuals.rs6060369 was also confirmed.

Let's see how many SNPS per trait:

```{r}
barplot(colSums(lfsr.mash<0.05),main="Number of Snps Significant at LFSR<0.05")
```

Let's generate the top SNPs per trait:

```{r}
colnames(lfsr.mash)=colnames(z.stat)
rownames(lfsr.mash)=rownames(z.stat)
data.frame(apply(lfsr.mash,2,function(x){(rownames(lfsr.mash)[order(x,decreasing=F)][1:10])}))
write.table(data.frame(apply(lfsr.mash,2,function(x){(rownames(lfsr.mash)[order(x,decreasing=F)][1:10])}))
,"top10pertrait.txt")
```
 
 Let's show how this integrates with the GTEX results:
```{r, topsnpinschizo}
 
topten=read.table("top10pertrait.txt",header=T,stringsAsFactors = F)
topten[1,"scz"]
```

Is an eQTL in Brain, Frontal Cortex [as shown here in the GteX browser](http://www.gtexportal.org/home/eqtls/bySnp?snpId=rs10484439&tissueName=Brain_Frontal_Cortex_BA9) representing a possible link to disease.

Now, we'd like to add pairwise sharing by magnitude and sign:

```{r pairwisesharing}
library("mashr")
se.matched=as.matrix(read.table("se.matched.txt"))
pm.mash.beta=post.means*se.matched
colnames(pm.mash.beta)=names
lfsr.mash.sig=lfsr.mash[rowSums(lfsr.mash<0.05)>0,]##only 137,223 are significant in at least one subgroup
pm.mash.sig=pm.mash.beta[rowSums(lfsr.mash<0.05)>0,]

signheatmap=compute.sharing.by.sign(lfsr.mash = lfsr.mash.sig,thresh = 0.05,pm.mash.beta = pm.mash.sig)
signheatmap[lower.tri(signheatmap)] <- NA
magheatmap=compute.mag.by.sharing(lfsr.mash = lfsr.mash.sig,thresh = 0.05,pm.mash.beta = pm.mash.sig)
magheatmap[lower.tri(magheatmap)] <- NA


library('colorRamps')
library('corrplot')
library(gplots)
library(ggplot2)

class(signheatmap)


heatmap.2(signheatmap,Rowv=FALSE,Colv=FALSE,
          symm=TRUE,dendrogram="none",density="none",trace="none",#col=redblue,
          col=blue2green,main=paste0("Pairwise Sharing by Sign"),
          cexRow=0.6,cexCol=0.5,cex.main=0.5,breaks=seq(0.7,1,0.01))


library('lattice')

clrs <- colorRampPalette(rev(c("#D73027","#FC8D59","#FEE090","#FFFFBF",
                               "#E0F3F8","#91BFDB","#4575B4")))(64)
#clrs[63:64] <- "darkviolet"
lat=signheatmap
lat[lower.tri(lat)] <- NA
print(levelplot(lat,col.regions = clrs,xlab = "",ylab = "",colorkey = TRUE,title(main="PairwiseSharingBySign")))


heatmap.2(magheatmap,Rowv=FALSE,Colv=FALSE,
          symm=TRUE,dendrogram="none",density="none",trace="none",#col=redblue,
          col=blue2green,main=paste0("Pairwise Sharing by Magnitude"),
          cexRow=0.6,cexCol=2,cex.main=0.5,#breaks=seq(0.35,1,0.01),
          labCol=NA)

library('lattice')

clrs <- colorRampPalette(rev(c("#D73027","#FC8D59","#FEE090","#FFFFBF",
                               "#E0F3F8","#91BFDB","#4575B4")))(64)
#clrs[63:64] <- "darkviolet"
absmagheatmap=compute.mag.by.sharing(lfsr.mash = lfsr.mash.sig,thresh = 0.05,pm.mash.beta = abs(pm.mash.sig))
absmagheatmap[lower.tri(absmagheatmap)] <- NA
lat=absmagheatmap
lat[lower.tri(lat)] <- NA
print(levelplot(lat,col.regions = clrs,xlab = "",ylab = "",colorkey = TRUE,title(main="PairwiseSharingByMagnitude")))
```

Now, let's look at sharing my asbolute value of magntiude:
```{r}

heatmap.2(signheatmap,Rowv=FALSE,Colv=FALSE,
          symm=TRUE,dendrogram="none",density="none",trace="none",#col=redblue,
          col=blue2green,main=paste0("Pairwise Sharing by Sign"),
          cexRow=0.6,cexCol=0.5,cex.main=0.5)
#,breaks=seq(0.7,1,0.01))

heatmap.2(1-signheatmap,Rowv=FALSE,Colv=FALSE,
          symm=TRUE,dendrogram="none",density="none",trace="none",#col=redblue,
          col=blue2green,main=paste0("Pairwise Sharing by Opposite Sign"),
          cexRow=0.6,cexCol=0.5,cex.main=0.5)
#,breaks=seq(0.7,1,0.01))



absmagheatmap=compute.mag.by.sharing(lfsr.mash = lfsr.mash.sig,thresh = 0.05,pm.mash.beta = abs(pm.mash.sig))
absmagheatmap[lower.tri(absmagheatmap)] <- NA
heatmap.2(absmagheatmap,Rowv=FALSE,Colv=FALSE,
          symm=TRUE,dendrogram="none",density="none",trace="none",#col=redblue,
          col=blue2green,main=paste0("Pairwise Sharing by abs(Magnitude)"),
          cexRow=0.6,cexCol=2,cex.main=0.5,#breaks=seq(0.35,1,0.01),
          labCol=NA)

heatmap.2(magheatmap,Rowv=FALSE,Colv=FALSE,
          symm=TRUE,dendrogram="none",density="none",trace="none",#col=redblue,
          col=blue2green,main=paste0("Pairwise Sharing by Magnitude"),
          cexRow=0.6,cexCol=2,cex.main=0.5,#breaks=seq(0.35,1,0.01),
          labCol=NA)
